#!/usr/bin/env python3
"""
ç¡¬ä»¶æ£€æµ‹æ¨¡å—
æä¾›ç¡¬ä»¶åç«¯æ£€æµ‹å’Œé…ç½®ä¼˜åŒ–åŠŸèƒ½
"""

import subprocess
import platform
from typing import Dict

try:
    import psutil
except ImportError as e:
    print(f"è¯·å®‰è£…ä¾èµ–: pip install psutil")
    raise e


class HardwareDetector:
    """ç¡¬ä»¶æ£€æµ‹å’Œé…ç½®ç±»"""
    
    @staticmethod
    def detect_available_backends() -> Dict[str, bool]:
        """æ£€æµ‹å¯ç”¨çš„ç¡¬ä»¶åç«¯"""
        backends = {
            'cpu': True,  # CPUæ€»æ˜¯å¯ç”¨çš„
            'cuda': False,
            'opencl': False,
            'metal': False
        }
        
        try:
            # æ£€æµ‹CUDA
            result = subprocess.run(['nvidia-smi'], capture_output=True, timeout=5)
            if result.returncode == 0:
                backends['cuda'] = True
        except (FileNotFoundError, subprocess.TimeoutExpired):
            pass
        
        try:
            # æ£€æµ‹OpenCLï¼ˆç®€åŒ–æ£€æµ‹ï¼‰
            if platform.system() in ['Linux', 'Windows']:
                backends['opencl'] = True
        except:
            pass
            
        try:
            # æ£€æµ‹Metalï¼ˆmacOSï¼‰
            if platform.system() == 'Darwin':
                backends['metal'] = True
        except:
            pass
        
        return backends
    
    @staticmethod
    def get_optimal_config(backend: str) -> Dict:
        """æ ¹æ®åç«¯è·å–æœ€ä¼˜é…ç½®"""
        configs = {
            'cpu': {
                'n_gpu_layers': 0,
                'n_threads': min(8, psutil.cpu_count())
            },
            'cuda': {
                'n_gpu_layers': 32,  # æ ¹æ®æ¨¡å‹è°ƒæ•´
                'n_threads': 1
            },
            'opencl': {
                'n_gpu_layers': 16,
                'n_threads': 2
            },
            'metal': {
                'n_gpu_layers': 32,
                'n_threads': 1
            }
        }
        return configs.get(backend, configs['cpu'])
    
    @staticmethod
    def get_system_info() -> Dict:
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        info = {
            'platform': platform.system(),
            'architecture': platform.machine(),
            'cpu_count': psutil.cpu_count(),
            'memory_total_gb': psutil.virtual_memory().total / (1024**3),
            'python_version': platform.python_version()
        }
        
        # å°è¯•è·å–GPUä¿¡æ¯
        try:
            result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader,nounits'], 
                                  capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                gpu_info = result.stdout.strip().split(',')
                if len(gpu_info) >= 2:
                    info['gpu_name'] = gpu_info[0].strip()
                    info['gpu_memory_mb'] = int(gpu_info[1].strip())
        except:
            info['gpu_name'] = 'Not available'
            info['gpu_memory_mb'] = 0
        
        return info
    
    @classmethod
    def print_system_info(cls):
        """æ‰“å°ç³»ç»Ÿä¿¡æ¯"""
        try:
            from colorama import Fore, Style
        except ImportError:
            Fore = Style = type('', (), {'RED': '', 'GREEN': '', 'CYAN': '', 'YELLOW': '', 'RESET_ALL': ''})()
        
        info = cls.get_system_info()
        backends = cls.detect_available_backends()
        
        print(f"\n{Fore.CYAN}ğŸ” ç³»ç»Ÿä¿¡æ¯:{Style.RESET_ALL}")
        print(f"  â€¢ æ“ä½œç³»ç»Ÿ: {info['platform']} ({info['architecture']})")
        print(f"  â€¢ CPUæ ¸å¿ƒæ•°: {info['cpu_count']}")
        print(f"  â€¢ å†…å­˜å¤§å°: {info['memory_total_gb']:.1f}GB")
        print(f"  â€¢ Pythonç‰ˆæœ¬: {info['python_version']}")
        print(f"  â€¢ GPU: {info['gpu_name']}")
        if info['gpu_memory_mb'] > 0:
            print(f"  â€¢ GPUæ˜¾å­˜: {info['gpu_memory_mb']/1024:.1f}GB")
        
        print(f"\n{Fore.CYAN}ğŸ–¥ï¸ å¯ç”¨åç«¯:{Style.RESET_ALL}")
        for backend, available in backends.items():
            status = f"{Fore.GREEN}âœ“{Style.RESET_ALL}" if available else f"{Fore.RED}âœ—{Style.RESET_ALL}"
            config = cls.get_optimal_config(backend)
            print(f"  {status} {backend.upper()}: {config}")
        print()